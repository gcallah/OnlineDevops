{% extends "base.html" %}
{% block content %}
<div class="module">
        <h1>
            Infrastructure as Code
        </h1>

        <figure>
            <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Evacuated_Highway_401_Color.jpg/580px-Evacuated_Highway_401_Color.jpg"
            width="21%">
            <figcaption>
            </figcaption>
        </figure>

        <figure>
            <iframe width="560" height="315"
                src="https://www.youtube.com/embed/OFGwZq0C-o4"
                frameborder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen>
            </iframe>
            <figcaption>
                Infrastructure as code and Docker
            </figcaption>
        </figure>

        <details>
            <summary class="sum1">
                Lesson 1: What Is Infrastructure as Code?
            </summary>

            <figure>
                <iframe width="560" height="315"
                    src="https://www.youtube.com/embed/RO7VcUAsf-I"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
                </iframe>
                <figcaption>
                    Infrastructure as code: What is it? Why is it important?
                    <br />
                    (This is a fantastic <b>3 minute</b> explanation of the
                    value of Infrastructure as Code.)
                </figcaption>
            </figure>

            <p>
                Infrastructure as code (IaC) as the idea that, rather than
                manually provisioning servers, or setting up hardware through a
                point-and-click GUI, the "server room" should itself be managed
                by code. That code can then be put under version control,
                tested, deployed with automated build tools, and so on.  The
                code also serves as necessarily up-to-date documentation of
                what the infrastructure is.
            </p>

            <p>
                The advantages of IaC can be divided into three main
                categories:
            </p>

            <ul class="nested">
                <li>
                    <span class="hilight">Cost savings</span>:
                    By automating hardware provisioning, the time of the people
                    who would have been doing that by hand is freed up for
                    other tasks.
                </li>

                <li>
                    <span class="hilight">Speed of deployment</span>:
                    It is much faster to configure infrastructure
                    by running a script than by manually setting a bunch
                    of parameters in a GUI interface.
                </li>

                <li>
                    <span class="hilight">Lower error rates</span>:
                    It is error-prone, because it is boring, too configure
                    systems "by hand." A script can be debugged once, and
                    then will run reliably again and again.
                    Furthermore, as code, the infrastructure can be read and 
                    reasoned about. It is very hard to do that with a bunch of
                    check-boxes!
                </li>
            </ul>

            <p>
                (Source:
                <a href="https://en.wikipedia.org/wiki/Infrastructure_as_Code">
                    Wikipedia on Infrastructure as Code
                </a>
                )
            </p>

            <p>
                <span class="hilight">A DevOps principle</span>:
                Asking people to <i>behave like automatons</i> 
                bores and dehumanizes
                them. Asking them to devise clever ways
                <i>to automate things</i>
                interests them, and treats them as the rational 
                beings that they are!
                <br />
                Aristotle: humans are
                <a href="https://en.wikipedia.org/wiki/Rational_animal">
                    rational animals</a>.
            </p>

        </details>

        <details>
            <summary class="sum1">
                Lesson 2: Available Tools
            </summary>

            <details>
                <summary class="sum2">
                    Puppet
                </summary>
                    <h5>Pros:</h5>
                    <ul class="nested">
                        <li>
                            Easy installation
                        </li>
                        <li>
                            Supports all majors operating systems
                        </li>
                        <li>
                            GUI is user friendly
                        </li>
                        <li>
                            Stable and mature solution
                        </li>
                    </ul>

                    <h5>Cons:</h5>
                    <ul class="nested">
                        <li>
                            New users must learn Puppet DSL (domain-specific
                            language)
                        </li>
                        <li>
                            Remote execution is challenging
                        </li>
                    </ul>

                    <h5>Overview:</h5>
                    <ul class="nested">

                        <p>
                            Puppet is a popular configuration management tool that automates infrastructure management. It is available FOSS and the paid version Puppet Enterprise is free for up to 10 nodes.
                        </p>

                        <p>
                            Puppet is configured in a client server architecture where the client has an agent installed which communicates with the puppetserver service running on the master server.
                        </p>

                        <p>
                            Puppet provides a way to describe a machine's state within code and keeps a machine compliant with the defined state automatically. It is somewhat similar to running a bunch of scripts. An important difference with Puppet versus scripts is that by default the Puppet agent checks the system's state for compliance every 30 minutes. Whereas unless it's scheduled, a script will need to be run again manually by the user. In addition to that, a script may not contain logic to prevent executing commands against things that are already compliant. In most cases, reconfiguring/reinstalling would disrupt operations. In contrast, Puppet is idempotent by default. When the Puppet agent runs, Puppet queries the system state and only executes commands on resources that do not match the state defined in code.
                        </p>

                    </ul>

                    <h5>Architecture:</h5>
                    <ul class="nested">

                        <p>
                            The Puppet master is installed on a linux server and an agent is installed on member nodes of most OS (linux, unix, mac, windows). When the agent runs on the member node, it composes "facts" based on system information (operating system, IP address, etc). The agent then sends the facts to the Puppet master and requests a catalog. The master uses the facts received to determine what should be in the catalog (desired state of the member node) and then sends the catalog back to the agent. When the agent receives the catalog, it checks whether each resource in the catalog matches the system's current state. If it doesn't, Puppet will perform the necessary changes. On agent run completetion, a report is generated and sent back to the master. The report is then stored within PuppetDB which is accessible on through the Puppet console through a browser.
                        </p>

                        <p>
                            All of the code, modules, and plugins are located on the Puppet master. Besides the Puppet agent, nothing resides on the member node. To ensure secure communication, agents request certificates from the master when the agent is installed so that all communication is done over HTTPS with SSL certificates. The master pulls code from whichever source control versioning system you use and keeps a cached copy of it on the local filesystem. The cached copy will be updated whenever an environment is deployed (development, test, production ,etc).
                        </p>

                        <p>
                            The Puppet code stack is designed to be modular for ease of use and flexibile deployments. Puppet programs are called manifests and are the core component of any Puppet module. A Puppet module can include many other components in addition to Puppet programs (*.pp). Static files, templates, tests, custom facts, and custom functions are usually included in modules found on the Puppet forge. The Puppet forge is a community module repository supervised by PuppetLabs. Many of the popular/most used modules were written and are fully supported by PuppetLabs themselves. If a module exists on the forge that meets your infrastructure needs, it's recommended to use it instead of reinventing the wheel. In practice, much of the modules found on an organization's Puppet master will be from the forge. The recommended practice when deciding how to use/stack various modules together is to use the "Roles and Profiles" paradigm.
                        </p>

                        <li>
                            A role in Puppet is a wrapper class that uses multiple profiles to build the node. Only one role can be assigned to a node.
                        </li>

                        <li>
                            A profile in Puppet is a wrapper class that uses multiple modules to configure a layered technology stack.
                        </li>

                        <li>
                            A module in Puppet manages one particular technology. Note that when writing modules yourself, there is no enforcement of this best practice. So even though you shouldn't, you can write modules that manage multiple technologies.
                        </li>

                        <p>
                            As Puppet roles contain profiles and profiles contain modules, conceptually the stack can be visualized with legos. If we were to build a unique lego city set (role), it could include several sets of city buildings (profiles) like a fire station, police station, and library. Those city buildings will include components (modules) that are composed of many bricks (resources) like a fire truck, or a police car. The profiles (buildings) and modules (vehicles) can be used/found outside this particular role (city), but there should be no other role that is exactly the same.
                        </p>

                    </ul>

                    <h5>Key terms:</h5>
                    <ul class="nested">


                        <li>
                            Agent - An executable installed on member nodes. The agent is responsible for communicating with the master to retrieve the catalog and perform any necessary changes on the system.
                        </li>

                        <li>
                            Catalog - Compiled by the Master of Masters (MoM) and applied by the agent. The catalog describes resources and the state they should be in.
                        </li>

                        <li>
                            Classes - A set of resources wrapped together to apply configurations.
                        </li>

                        <li>
                            Facts - Pre-set variables about the system resolved at run time that are globally available within the manifests.
                        </li>

                        <li>
                            Facter - Puppet's cross-platform system profiling library. It discovers and generates the systems "facts" which are exposed to manifests as variables.
                        </li>

                        <li>
                            Forge - Puppet Community module repository
                        </li>

                        <li>
                            Hiera - Puppet's builtin key/value lookup system which abstracts data from Puppet code.
                        </li>

                        <li>
                            Manifests - Files that contain Puppet code ending with a *.pp extension (puppet program). It is convention to have the manifests named init.pp, install.pp, config.pp, service.pp. Where init is the main entrypoint of the module and will include the other classes. Install, config, and service by convention contains resources that would install packages, configure system settings, and manage services respectively.
                        </li>

                        <li>
                            Master - A server where at least the puppetserver service is running. On a monolithic installation, all Puppet services reside on the same master (puppetserver, puppetDB, console, etc.). On a "split installation" the ancillary services are installed on other servers.
                        </li>

                        <li>
                            Modules - A packaged collection of files and directories to manage a particular techonology.
                        </li>

                        <li>
                            Resources - The core components of Puppet code. Resources have a type, name, and one or more attributes.
                        </li>                    
                        
                    </ul>

                    <h5>Installation:</h5>
                    <ul class="nested">

                        <p>
                            Puppet is a cross platform product that can be installed on most operating systems. The only requirement is that the Puppet master be installed on a linux machine. The agent can be installed on OS of choice. Note that when installing Puppet agents, it is most common to install them on servers, but the Puppet agent can also be installed on other systems such as Desktop PCs and network appliances.
                        </p>

			<p>
			  To install Puppet server, follow the easy steps from the <a href="https://puppet.com/docs/pe/2018.1/installing_pe.html">installing Puppet Enterprise</a> official documentation.
			</p>

			<p>
			  To install Puppet agent(s), follow the easy steps from the <a href="https://puppet.com/docs/pe/2018.1/installing_agents.html">Installing agents</a> official documentation.
			</p>
                    </ul>

                    <h5>Writing infrastructure code:</h5>
                    <ul class="nested">

                        <p>
                            Writing modules customized to your organizational needs is a key component to a successful Puppet deployment. Your Puppet module may contain many directories such as: manifests, files, templates, lib, facts.d, examples, spec, functions, types, tasks. Initially, focus should primarily be on manifests as these are the puppet programs that comprise most, if not all of the configurations.
                        </p>

                        <p>
                            Puppet programs are written in Puppet's own DSL (Domain Specific Language) but the syntax of it isn't very different from other declarative languages. For example, PowerShell DSC (Desired State Configuration) is nearly one to one syntactically to Puppet DSL. Being a declarative language, code within the Puppet programs will not be executed top down unless specifically ordered to do so with resource meta parameters. The idea is that your code defines how a system should be and Puppet does the work of deciding what execution order is the most optimal for the system. As previously mentioned, this can and should be explicitly overwritten to ensure proper deployment. For example ensuring a package resource runs before a dependent service resource does.
                        </p>

                        <p>
                            Let's go through writing a simple module that manages Docker (a great Docker module written by PuppetLabs already exists on the <a href="https://forge.puppet.com/puppetlabs/docker">forge</a>) as an example.
                        </p>

                        <p>
                            The name of the module is mydocker and the main Puppet program within the manifest is init.pp.

                            The empty init.pp will just have a class with the name of the module.

                            <pre>
                                <code>
    # mydocker/manifests/init.pp
    class mydocker {

    }
                                </code>
                            </pre>
                        </p>

                        <p>
                            Let's say we created 3 more Puppet programs within the module install.pp, config.pp, service.pp. The class namespace is &lt;module name&gt;:&lt;puppet program name&gt;.

                            <pre>
                                <code>
    # mydocker/manifests/install.pp
    class mydocker::install {

    }

    # mydocker/manifests/config.pp
    class mydocker::config {

    }

    # mydocker/manifests/service.pp
    class mydocker::service {

    }                 
                                </code>
                            </pre>
                        </p>

                        <p>
                            Now let's include these classes within our "main" class init.pp

                            <pre>
                                <code>
    # mydocker/manifests/init.pp
    class mydocker {
      include mydocker::install
      include mydocker::config
      include mydocker::service

      Class['mydocker::install'] -> Class['mydocker::config'] -> Class['mydocker::service']
    }
                                </code>
                            </pre>
                        </p>

                        <p>
                            The reserved keyword "include" declares a class, but in practice the reserved keyword "contain" is often used instead. While both include and contain declare classes, contain "contains" resources within it's class while include my not. When putting together a stack of modules, include declares all of the class' resources within the catalog. Remember that unless specifically stated, Puppet decides how the execution of those resources will be ordered in the catalog. So let's say you have modules to manage Docker and another to manage an application running inside a Docker container.

                            <pre>
                                <code>
    # profiles/manifests/website.pp
    class profile::website {
      include mydocker
      include djangoapp
    }
                                </code>
                            </pre>
                        </p>

                        <p>
                            Puppet is "usually" smart enough to know resources from the mydocker module need to be run before resource in the djangoapp module deploy the application within a Docker container. But, "usually" is not good enough. To ensure Docker resources execute first, declare the modules with "contain" and explicity order the classes.

                            <pre>
                                <code>
    # profiles/manifests/website.pp
    class profile::website {
      contain mydocker
      contain djangoapp

      Class['mydocker'] -> Class['djangoapp']
    }
                                </code>
                            </pre>
                        </p>

                        <p>
                            This way resources in the djangoapp module will ALWAYS execute after resources in mydocker module.

                            Going back to our mydocker module, we will need install some packages to have docker installed. Let's put the resources within the install.pp class to do exactly that.

                            <pre>
                                <code>
    # mydocker/manifests/install.pp
    class mydocker::install {
      # Setup the repository

      # update the apt package index
      exec { 'update apt-get':
        command => '/usr/bin/apt-get update',
        onlyif  => "/bin/sh -c '[ ! -f /var/cache/apt/pkgcache.bin ] || /usr/bin/find /etc/apt/* -cnewer /var/cache/apt/pkgcache.bin | /bin/grep . > /dev/null'",
      }

      # install a single package to allow apt to use a repository over HTTPS
      package { 'apt-transport-https':
        ensure  => present,
        require => Exec['update apt-get'],
      }

      # install a multiple packages passed as an array to a single resource to allow apt to use a repository over HTTPS
      package { [
        'ca-certificates',
        'curl',
        'software-properties-common',
      ]:
        ensure => present,
        require => Exec['update apt-get'],
      }

      # add Docker's official GPG key
      exec { 'add docker gpg key':
        command => '/usr/bin/curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -',
        unless  => '/usr/bin/apt-key fingerprint 0EBFCD88',
        require => Exec['update apt-get'],
      }

      # Install Docker CE
      
      # Update the apt package index after repo setup
      package { 'docker-ce':
        ensure   => present,
        provider => apt,
        require  => Exec['add docker gpg key'],
      }
    }
                                </code>
                            </pre>
                        </p>

                            <p>
                                Two resource types were used in mydocker::install, exec and package. Refer the Puppet's documentation/reference on <a href="https://puppet.com/docs/puppet/5.3/type.html">resource types </a>.

                                The exec resource executes external commands and package manages packages. All Puppet resources follow the convention
                                <pre>
                                    <code>
    &lt;resource type&gt; { '&lt;resource title&gt;':
        &lt;attribute&gt; => &lt;value&gt;,
    }                                        
                                    </code>
                                </pre>
                            </p>

                            <p>
                                Every resource also sets the namevar attribute to the resource's title by default if namevar is not explicity stated.
                                <pre>
                                    <code>
    # namevar explicitly stated
    package { 'install docker':
      name   => 'docker-ce',
      ensure => 'present',
    }

    # namevar omitted and resolves to resource title
    package { 'docker-ce':
      ensure   => present,
      provider => apt,
    }
                                    </code>
                                </pre>
                            </p>

                            <p>
                                The exec resource has an attribute "command" which is the fully scoped command to be run on a system. Exec's should be used with caution as these resources are not idempotent by default and require greater understanding of the commands being run. 
                            </p>

                            <p>
                                To ensure that the exec command isn't run every single time the Puppet agent runs, two attributes which both take commands as values (onlyif and unless) are used to demonstrate 2 of several ways to preserve idempotency. 
                            </p>

                            <p>
                                The onlyif attribute will only execute the "command" attribute's value in the shell if the "onlyif" attribute's value exits 0. The unless attribute will allow the "command" attribute to run except when the "unless" attribute's value exits 0. 
                            </p>

                            <p>
                                When onlyif exits 1 or unless exits 0, neither of the commands in the exec resource are executed, ensuring agent runs on systems that match the desired state don't change anything or waste unecessary system resources.
                            </p>

                            <p>
                                The package resource attributes used are: ensure, require, and provider. Of these 3, only the ensure attribute is required. Just like it sounds, the ensure attribute a package is &lt;something&gt; on the system. Valid ensure values are: present, installed, absent, purged, held, latest and can also be a specific version.
                            </p>

                            <p>
                                The require attribute is a metaparameter which as the name implies, deals with resource ordering. For the most part, the require attribute is not needed in mydocker::install as Puppet is usually smart enough to order the resources properly. But, to ensure the catalog is composed how we expect it all the time and to demonstrate resource ordering, the require attribute was used. 
                            </p>

                            <p>
                                There are 4 metaparameters that specify resource ordering: before, notify, require, subscribe. Before and notify ensure that the resource must run before something else. Notify also signals the dependent resource to refresh. This is used in such cases as a web application package resource that notifies a web service resource to refresh (restart) after the package is installed.
                            </p>

                            <p>
                                The provider attribute tells the resource package resource what provider to use when installing packages. In practice, the provider attribute is used sparingly as Puppet is smart enough to automatically select the appropriate provider, but sometimes you may want Puppet to use the rpm provider instead of yum on RedHat.
                            </p>

                            <p>
                                Now that the mydocker::install class installs docker, let's add some configurations (users, permissions, files, etc) to the mydocker::config class.

                                <pre>
                                    <code>
    # mydocker/manifests/config.pp
    class { 'mydocker::config':
      # enable a non-root user to use Docker

      # configure Docker group
      group { 'docker':
        ensure => present,
        gid    => '502',
      }

      # ensure that the user account exists, is configured, and added to docker group
      user { 'yourname':
        ensure           => present,
        gid              => '95555510',
        home             => '/home/myname',
        groups           => 'docker',
        password         => 'mypasswd',
        password_max_age => '9999',
        password_min_age => '0',
        shell            => '/bin/bash',
        uid              => '95555510',
      }

      # allow users to view puppet agent folders/files on the system
      file { '/opt/puppetlabs':
        ensure  => directory,
        mode    => '0755',
        recurse => true,
      }
    }                                        
                                    </code>
                                </pre>
                            </p>

                            <p>
                                The resources used within the mydocker::config class are: group, user, and file. The group resource ensures the presence of the docker group. Since mydocker::install is ordered to execute first and creates the docker group, this resource doesn't do anything. It is still within the module because we want to ensure the system state stays that way. If the docker group gid changes, or perhaps someone fat fingers a delete command and accidentally removes the docker group, Puppet will correct the change.
                            </p>

                            <p>
                                The user resource ensures that a local account is created on the system and is a member of the docker group. Notice that the user's password is in plain text. This is done for simplicity, but can and should be encrypted. To use an ecrypted value, we could leverage Puppet's builtin key/value lookup system with eyaml. Eyaml is used to encrypt an input string of the user's password accessible from the manifest. The private key to decrypt the string resides on the Puppet master. The use hiera, a hiera.yaml file is created to decide which data source to use (like an index). The data sources (dictionaries) are also yaml files but only contain hashes of key value pairs. We will create a data folder at the root of our module and then put a data source within it called common.yaml. Hiera is "hierarchical" in that multiple data sources could be created with duplicate key/value pairs. The value that Puppet ultimately uses is dependent on the hiera hierarchy layer. A common implementation of hiera hierarchy layers in order is: node, os, environment. Thus, there can be data sources for a specific node (myserver.yaml), OS (RedHat.yaml), and environment (test.yaml). The key/value pairs within all of those data sources will be available to the manifest. What if a key exists in more than one data source? By default hiera tries the data source at the "top" of the hierarchy, and continues moving "down" the hierarchy until it finds a match. Merge behavior can be overridden, but this is the default implementation.

                                <pre>
                                    <code>
    # mydocker/manifests/config.pp
    class mydocker::config {
      # ensure user exists and lookup the value (encrypted) of the password from hiera
      user { 'yourname':
        ensure           => present,
        gid              => '95555510',
        home             => '/home/myname',
        groups           => 'docker',
        password         => lookup('mypasswd'),
        password_max_age => '9999',
        password_min_age => '0',
        shell            => '/bin/bash',
        uid              => '95555510',
      }
    }

    # mydocker/hiera.yaml
    ---
    version: 5

    defaults:
      datadir: data
      data_hash: yaml_data

    hierarchy: 

     - name: "common"
       "path: common.eyaml"

    # mydocker/data/common.eyaml
    ---
    mydocker::mypasswd: ENC[PKCS7...]

    # puppetmaster:/etc/puppetlabs/puppet/hiera.yaml
    ---
    version: 5

    defaults:
      datadir: "/etc/puppetlabs/code/environments/%{::environment}/hieradata"
      data_hash: yaml_data

    hierarchy:

     - name: "Encrypted Per-node data"
       path: "nodes/%{trusted.certname}.eyaml"
       lookup_key: eyaml_lookup_key
       options: pkcs7_private_key: /etc/puppetlabs/puppet/keys/private_key.pkcs7.pem
            pkcs7_public_key: /etc/puppetlabs/puppet/keys/public_key.pkcs7.pem

      - name: "Unencrypted Per-node data"
        path: "nodes/%{trusted.certname}.yaml"

      - name: "Encrypted OS data"
        path: "os/%{::osfamily}.eyaml"
        lookup_key: eyaml_lookup_key
        options:
          pkcs7_private_key: /etc/puppetlabs/puppet/keys/private_key.pkcs7.pem
          pkcs7_public_key: /etc/puppetlabs/puppet/keys/public_key.pkcs7.pem

      - name: "Unencrypted OS data"
        path: "os/%{::osfamily}.yaml"

      - name: "Encrypted environment data"
        path: "environment/%{::environment}.eyaml"
        lookup_key: eyaml_lookup_key
        options:
          pkcs7_private_key: /etc/puppetlabs/puppet/keys/private_key.pkcs7.pem
          pkcs7_public_key: /etc/puppetlabs/puppet/keys/public_key.pkcs7.pem

      - name: "Unencrypted environment data"
        path: "environment/%{::environment}.yaml"

      - name: "Encrypted common"
        path: "common.eyaml"
        lookup_key: eyaml_lookup_key
        options:
          pkcs7_private_key: /etc/puppetlabs/puppet/keys/private_key.pkcs7.pem
          pkcs7_public_key: /etc/puppetlabs/puppet/keys/public_key.pkcs7.pem

      - name: "Unencrypted common"
        path: "common.yaml"

                                    </code>
                                </pre>
                            </p>

                            <p>
                                The mydocker::install class changed only in that the password attribute's value calls the builtin lookup function to find a key in hiera named mypasswd. The hiera.yaml file at the root of the module specifies that there are data sources within the module itself that hiera should trying finding the mypasswd key first and how the data sources are ordered. In this case there is only one data source common.eyaml. The key exists and be decrypted by the master at catalog compilation time. If the key didn't exist, hiera will lookoutside the module and will check the other two scopes (environment and global). The hiera.yaml file that resides on the Puppet master for the global layer is shown within the example. Notice the hierarchy for encrypted eyaml and unencrypted yaml files.
                            </p>

                            <p>
                                Finally let's add a service resource to service.pp to ensure the docker service is always running.

                                <pre>
                                    <code>
    # mydocker/manifests/service.pp
    class { 'mydocker::service':
      service { 'docker':
        ensure => running,
        enable => true,
      }
    }
                                    </code>
                                </pre>
                            </p>

                            <p>
                                The docker service resources ensures that docker is always running. So if someone stops the service, Puppet will start it again. It also makes sure that the docker service is enabled to start at boot.
                            </p>

                        </p>
                    </ul>

                    <h5>Add-ons:</h5>
                    <ul class="nested">

                        <p>
                            Puppet offers additional (paid) products to form a more complete DevOps ecosystem.
                        </p>

                        <li>
                            Puppet Enterprise - PE is fundamentaly the same as the FOSS version, but adds quality of life features useful in managing a large infrastructure. The Puppet Enterprise console is a web GUI which facilitates the management, organization, analytics, and monitoring of the Puppet infrastructure in an easy to pick up interface. Most of the functionality in PE can be replicated in FOSS, but without a graphical interface. Unlike the other paid additions, PE is free and doesn't expire for up to 10 nodes.
                        </li>

                        <p>
                            The following add ons are free with a 30 day trial
                        </p>

                        <li>
                            Continuous Delivery for Puppet Enterprise - Maintainers of Puppet code in an organization follow the same DevOps cycle as application developers. CD4PE is a product that provides a pipeline for Puppeteers to develop, test, and deploy their infrastructure code in an automated fashion; complete with bells and whistles.
                        </li>
                        
                        <li>
                            Puppet Discovery - The Puppet master only knows about the nodes in the organization that have the Puppet agent installed on it. Puppet Discovery probes the organization over SSH/WinRM to "discover" and return information on nodes regardless of whether the Puppet agent is installed on it.
                        </li>
                        
                        <li>
                            Puppet Pipelines - CI/CD Pipeline for applications and containers. It can be used as a stand alone product to deploy a CI/CD platform, but more often than not will be used as the base platform that other standout products integrate with (Jira, Jenkins, etc.)
                        </li>
                        
                        <li>
                            Puppet Insights - Puppet's take on analytics. Insight measures and optimizes DevOps practices by aggregating, analyzing, and visualizing key metrics.
                        </li>

                    </ul>

                    <p>
                    <a href="https://gcallah.github.io/DevOps/deployment/puppet.html"> More on puppet </a>
                    </p>

            </details>

            <details>
                <summary class="sum2">
                  Chef
                </summary>
                <h5>Pros:</h5>
                <ul class="nested">
                    <li>
                        Meant to be used by programmers
                    </li>
                    <li>
                        Useful for large-scale development
                    </li>
                    <li>
                        Stable and mature solution
                    </li>
                    <li>
                        Good version control capabilities
                    </li>
                </ul>
                <h5>Cons:</h5>
                <ul class="nested">
                    <li>
                        Complicated tool to use
                    </li>
                    <li>
                        Familiarity with Ruby is required
                    </li>
                    <li>
                        Documentation can be overwhelming
                    </li>
                </ul>
                <p>
                <a href="https://gcallah.github.io/DevOps/deployment/chef.html"> More on Chef </a>
                </p>
            </details>
            <details>
                <summary class="sum2">
                  Ansible
                </summary>
                <h5>Pros:</h5>
                <ul class="nested">
                    <li>
                        Easy and fast deployment
                    </li>
                    <li>
                        Secure SSH connection
                    </li>
                    <li>
                        Meant for environments that can scale rapidly
                    </li>
                    <li>
                        Push and pull models are supported
                    </li>
                </ul>
                <h5>Cons:</h5>
                <ul class="nested">
                    <li>
                        Basic support for Windows
                    </li>
                    <li>
                        GUI is not very interactive
                    </li>
                    <li>
                        Difficult to locate syntax errors with YAML
                    </li>
                </ul>
                <p>
                <a href="https://gcallah.github.io/DevOps/deployment/ansible.html"> More on Ansible </a>
                </p>
            </details>
            <details>
                <summary class="sum2">
                  SaltStack
               </summary>
                <h5>Pros:</h5>
                <ul class="nested">
                    <li>
                        Implemented in Python and controlled with YAML files
                    which are simple to understand
                    </li>
                    <li>
                        Fast communication between master and client
                    </li>
                    <li>
                        Provides high scalability and resiliency
                    </li>
                    <li>
                        Vibrant support community
                    </li>
                </ul>
                <h5>Cons:</h5>
                <ul class="nested">
                    <li>
                        Difficult to set up
                    </li>
                    <li>
                        Salt GUI is under development
                    </li>
                    <li>
                        Does not support a variety of Operating Systems
                    </li>
                </ul>
            </details>

        </details>

        <details>
            <summary class="sum1">
                Lesson 3: Running Docker
            </summary>

                <p class="author">
                    by
                    <br />
                    Prashantkumar Patel and Prof. Callahan
                </p>


                <p>
                    <span class="hilight">First thing</span>:
                    Make sure you have Docker installed! You
                    won't get any further in following along on your laptop 
                    if you do not.
                </p>

                <p>
                    <span class="hilight">Secondly</span>:
                    Please clone (if you have not already) our online DevOps
                    repo:
                    <br />
                    <code>
                        git clone https://github.com/gcallah/OnlineDevops.git
                    </code>
                </p>

                <p>
                    Once you have cloned that repo, please open two shells: in
                    one, we will look at your local environment, and in the
                    other we will explore the container.
                </p>

                <p>
                    In one of the two shells, in your OnlineDevops directory,
                    please run:
                    <br />
                    <code>
                        ./container.sh
                    </code>
                    <br />
                    That should put you inside the OnlineDevops container: if
                    that command worked, you should see your prompt change.
                    <br />
                    If it did, let's explore the shells you are in a little to
                    try to understand better what a container is.
                    <br />
                    I am going to proceed by showing you the results of running
                    the same command inside and outside the container on my
                    machine: your results will be different, but similar, to
                    mine.
                </p>

                <p>
                    First of all, let's look at the root file system, inside
                    and outside the container:
                </p>

                <p>
                    Outside the container:
                    <br />
                    <code>ls / </code>
                    <br />
                    <pre>
    Macintosh:OnlineDevops gcallah$ ls /
    Applications            bin                net
    Library                cores                opt
    Network                debug.txt            private
    Shockwave Log            debug.txt.1            sbin
    System                dev                tmp
    User Guides And Information    etc                usr
    User Information        home                var
    Users                installer.failurerequests
    Volumes                logFile.xsl
                    </pre>
                    
                </p>

                <p>
                    Inside the container:
                    <br />
                    <code>ls / </code>
                    <br />
                    <pre>
    root@a5dd222a9812:/home/DevOps# ls /
    bin   dev  home  lib64    mnt  proc           root  sbin  sys    usr
    boot  etc  lib     media    opt  requirements.txt  run   srv   tmp    var
                    </pre>
                </p>

                <p>
                    What's of note here: From outside and from inside the
                    container, we see completely different file systems!
                    Inside the container, we are in a 
                    <a href="https://en.wikipedia.org/wiki/Chroot">chroot</a>
                    file system.
                </p>

                <p>
                    What about our view of what processes are running?
                    <br />
                    Outside the container we see:
                    <br />
                    <code>ps -ef | wc -l</code>
                    <br />
                    <pre>
     Macintosh:OnlineDevops gcallah$ ps -ef | wc -l
     667
                    </pre>
                </p>


                <p>
                   From outside the container, the OS lists 667 processes
                   as running on my Mac. 
                </p>


                <p>
                    Inside the container we see:
                    <br />
                    <code>ps -ef</code>
                    <br />
                    <pre>
    root@a5dd222a9812:/home/DevOps# ps -ef
    UID        PID  PPID  C STIME TTY          TIME CMD
    root         1     0  0 Oct25 pts/0    00:00:00 bash
    root       192     1  0 21:18 pts/0    00:00:00 ps -ef
                    </pre>
                </p>

                <p>
                   From inside the container, there are two processes running! 
                   The container has process isolation from the host. It has
                   its own
                   <a href="https://en.wikipedia.org/wiki/Linux_namespaces">process 
                    namespace</a> separate from its host's namespace and from
                   the namespace of any other containers running on that host.
                   The separate namespace also provides the container with its
                   own hostname, its own user IDs, and its own inter-process
                   communication names.
                </p>

                <h4>
                    Some Docker commands
                </h4>

                <p>
                    Now let's look at what some Docker commands are available,
                    and what they do.
                </p>

                <p>
                    <code>docker ps</code>
                </p>

                <p>
                    This will list your currently running Docker images. When 
                    Prof. Callahan runs it while preparing this lecture, he
                    sees:
                    <br />
                    <pre>
    Macintosh:OnlineDevops gcallah$ docker ps
    CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES
    429ff1a37d21        devops              "bash"              11 seconds ago
    Up 6 seconds        0.0.0.0:32768-&gt;8000/tcp   stupefied_swanson
                    </pre>
                </p>
                <p>
                    (The 0.0.0.0 is the IP address to use for the container,
                    and 32768 is the port it is using.)
                </p>

                <p>
                    <code>docker ps -a</code> 
                    <br />
                    This will list <i>all</i> images that have been run
                    on the system, not just those that are active:
                    <br />
                        
                        <pre>
    Macintosh:OnlineDevops gcallah$ docker ps -a
    CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                           PORTS                    NAMES
    c560c3729d7e        devops              "bash"              18 minutes ago
    Up 18 minutes                    0.0.0.0:8000-&gt;8000/tcp   brave_kirch
    429ff1a37d21        devops              "bash"              About an hour ago   Exited (130) 44 minutes ago                               stupefied_swanson
    32b272487675        devops              "bash"              5 days ago          Created                                                   wonderful_heyrovsky
    a5dd222a9812        devops              "bash"              10 days ago         Exited (130) About an hour ago                            naughty_beaver
    e82e4fb65823        devops              "bash"              11 days ago         Exited (130) 11 days ago                                  youthful_noyce
    0433f774c394        devops              "bash"              11 days ago         Created                                                   stupefied_hawking
    1ba39e023554        devops              "bash"              11 days ago         Created                                                   practical_ptolemy
    4a6bc8cf7ab0        devops              "bash"              11 days ago         Created                                                   vigilant_curie
    47cb14ca5b1b        devops              "bash"              2 weeks ago
    Exited (255) 11 days ago         0.0.0.0:8000-&gt;8000/tcp   determined_goldwasser
    7af5f14f88d9        f418f33054e8        "bash"              2 weeks ago         Exited (130) 2 weeks ago                                  modest_hypatia
    e3292cdc1449        indra               "bash"              2 weeks ago         Exited (130) 2 weeks ago                                  competent_hugle
    3ad630752ebf        indra               "bash"              2 weeks ago         Exited (130) 2 weeks ago                                  amazing_meitner
    fe439d8e15c2        indra               "bash"              2 weeks ago         Exited (130) 2 weeks a
                        </pre>
                </p>

                <p>
                   <code>docker images</code>
                </p>

                <p>
                    This command should give you the list of images
                    that are available on the system. For example
                    in Prashant's system it looks something like
                    this:
                <br />
                    <pre>
    ENG-EJC369-02:$ docker images
    REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
    gcallah/jenkins_py3   latest              21130e104ca1        4 weeks ago         742MB
    jenkins               latest              cd14cecfdb3a        6 weeks ago         696MB
    gcallah/indra         v7                  ad9670e8b27f        2 months ago        946MB
    python                latest              efb6baa1169f        5 months ago        691MB
    ubuntu                latest              f975c5035748        5 months ago        112MB
    gcallah/emu86         v4                  f6833ae8bf9e        6 months ago        776MB
    gcallah/django        latest              432de70e222d        6 months ago        769MB
    bash                  latest              59507b30b48a        6 months ago        12.2MB
    alpine                latest              3fd9065eaf02        7 months ago        4.15MB
                    </pre>
                </p>

                <p>
                    In the above listing, the <code>nginx</code> image
                    is not installed. Running the following command will
                    pull the nginx image from DockerHub, which is like GitHub,
                    but for docker images.
                </p>

                <p>
                <code>
                    docker pull nginx
                </code>
                </p>
                <p>
                    Now that you have installed the nginx image,
                    just run the docker images command again,
                    in the list you should see ngnix image as below:
                <br />
                    <pre>
    ENG-EJC369-02:$ docker images
    REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
    nginx                 latest              71c43202b8ac        7 hours ago         109MB
    gcallah/jenkins_py3   latest              21130e104ca1        4 weeks ago         742MB
    jenkins               latest              cd14cecfdb3a        6 weeks ago         696MB
    gcallah/indra         v7                  ad9670e8b27f        2 months ago        946MB
    python                latest              efb6baa1169f        5 months ago        691MB
    ubuntu                latest              f975c5035748        5 months ago        112MB
    gcallah/emu86         v4                  f6833ae8bf9e        6 months ago        776MB
    gcallah/django        latest              432de70e222d        6 months ago        769MB
    bash                  latest              59507b30b48a        6 months ago        12.2MB
    alpine                latest              3fd9065eaf02        7 months ago        4.15MB
                    </pre>
                </p>

                <p>
                    (You can put an image <i>into</i> DockerHub using
                    <code>docker push</code>.)
                </p>

                <h4>
                    Download website code
                </h4>

                <p>
                    Ok now that you have download the nginx image,
                    let's download the static website that you
                    are going to host inside the docker container.
                    We are going to use the algorithms website for
                    another course.
                    You can find the code for the website 
                    <a href="http://gitub.com/gcallah/algorithms.git">
                    here.
                    </a>
                </p>

                <p>
                    Please remember the location where you have
                    cloned the repository. Prashant has cloned it in
                    <code> /Users/prashant/school/algorithms</code>.
                    Your location will be different than this, please note
                    the location.
                </p>

                <h4>
                    Let's make a container
                </h4>

                <p>
                    Ok, so we have downloaded the nginx image and
                    the code of the website which we want to host
                    All we need to do is just make a container
                    out of the image. We will put the code of
                    website inside the container so that the
                    webserver which is nginx in our case can
                    read the html files and host it in local
                    server.
                    The command for that is as shown below.
                </p>
                <p>
                    <code>
                        docker run --name algo_website -p 127.0.0.1:8080:80
                        -v
                        /Users/prashant/school/algos/:/usr/share/nginx/html
                        -d nginx
                    </code>
                </p>

                <p>
                    Please don't forget to change the location of
                     algorithms directory in above command.
                     After you run the command open the browser
                     and type <code>http://localhost:8080</code>
                     and you should be able to see the webpage.
                     Windows user should use the address
                     <code>http://0.0.0.0:8080</code>
                     instead of localhost.
                </p>

                <p>
                    After we leave the container, we can get rid of it using
                    <code>docker rm algo_website</code>.
                    If we need to remove a container that is still running,
                    we will have to stop it first with
                    <code>docker stop</code>.
                </p>

        </details>

        <details>
            <summary class="sum1">
                Our Docker Implementation
            </summary>

            <p>
                We use Docker in our projects for two main reasons, with a
                third to come:
            </p>

            <ol class="nested">
                <li>
                    To set up a local version of a web server that will be
                    configured "just like" our production server. ("Just like"
                    is in quotes because that is always the ideal, but it may
                    not be fully achieved.)
                </li>
                <li>
                    To provide our full suite of development tools, such as the
                    correct Python version, make, flake8, various Python
                    libraries, etc., in one simple to build package, so all
                    developer's have a consistent environment.
                </li>
                <li>
                    Ultimately, we should be deploying the container where we
                    locally test our web servers right into production,
                    guaranteeing that development and production are identical
                    environments. Unfortunately, at the moment, the places we
                    are hosting do not support that. We are exploring other
                    options.
                </li>

            </ol>

            <p>
            So we need to know how to create the right container for 
            each project. 
            Each project we work on should have a 
            <code>Dockerfile</code> consisting of instructions
            on how to build the image for that project, a
            <code>requirements.txt</code> listing what
            external modules need to be included in the image,
            and a line in the project's <code>makefile</code>
            automating the build of the image.
            This is <i>infrastructure as code</i>, since the infrastructure for 
            the project is built from these files of code.
            </p>

            <p>
                So, in the <code>makefile</code> we want something 
                like:
            </p>

            <p>
            <code>
        container: $(DOCKER_DIR)/Dockerfile  $(DOCKER_DIR)/requirements.txt
        <br />
            &nbsp; &nbsp; &nbsp; &nbsp; docker build -t indra docker
            </code>
            </p>

            <ul class="nested">
                <li>
                    <a href="https://github.com/gcallah/indras_net/blob/master/docker/Dockerfile">
                        Here is a sample Dockerfile.
                    </a>
                    <br />
                    The <code>FROM python:3.6.0</code> 
                    command says what base image to build
                    our image from.
                    <br />
                    The <code>COPY requirements.txt /requirements.txt</code>
                    line brings the requirements file inside the container.
                    <br />
                    The line
                    <code>RUN pip install -r requirements.txt</code> 
                    installs everything from the requirements file in the
                    container.
                    <br />
                    The line
                    <code>ENV user_type TERMINAL</code> 
                    sets an environment variable (<code>user_type</code>)
                    that will be available inside the container.
                    <br />
                    <code>WORKDIR /home/IndrasNet/</code>
                    sets the starting directory inside the container.
                </li>

                <li>
                    <a href="https://github.com/gcallah/indras_net/blob/master/docker/requirements.txt">
                        Here is the requirements file it uses.
                    </a>
                </li>
            </ul>
        </details>

        <details>
            <summary class="sum1">
                Our More Advanced Docker Usage
            </summary>

            <p>
                In the Online DevOps course project, we use a more advanced
                Docker setup: we employ
                <a href="https://docs.docker.com/compose/">Docker Compose</a>
                to define and run an application composed of more than
                one Docker container.
            </p>

            <p>
                Docker Compose use a 
                <a href="https://en.wikipedia.org/wiki/YAML">YAML</a>
                file to specify the configuration of a multi-container
                Docker app.
            </p>

            <p>
                In the Online DevOps course setup, we are running just two
                containers: one to run the MySQL database, and the other
                to run our Django web server. But other Docker Compose
                setups might include a web server, a load balancer,
                a database, an authentication server, and more!
                <br />
                <a
                   href="https://github.com/gcallah/OnlineDevops/blob/master/docker-compose.yml">Here</a>
                is the YAML file that specifies our two-container
                application.
            </p>

        </details>

        <details>
            <summary class="sum1">
                Other Readings
            </summary>

            <ul class="nested">
               <li>
                    <a href="https://puppet.com/blog/containers-are-eating-world">
                        Containers are eating the world
                    </a>
                </li>

                <li>
                    <a href="https://www.ibm.com/developerworks/java/library/a-devops2/index.html">
                        Infrastructure automation
                    </a>
                </li>

                <li>
                    <a href="https://www.ibm.com/developerworks/library/d-bbd-guide-iac/">
                        A Behavior Driven Developer's guide to Infrastructure as Code
                    </a>
                </li>

            </ul>

        </details>


        {% include 'quiz.html' %}

{% endblock content %}
